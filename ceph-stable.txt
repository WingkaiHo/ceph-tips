假设小型生产环境使用ceph集群， datanode节点数目为4，每个datanode包含3个磁盘（osd）， 每个磁盘（osd）空间为2TB， 磁盘使用率75%， 磁盘写入速度50MB/s， 备份数目3 计算集群一年期丢失数目据概率


P: 丢失所有副本的概率
N: 整个Ceph Pool中OSD的数量（4*3 = 12 4： datanode 数目， 3每个datanode有3个磁盘）
R: 副本数 （3个备份）
S: 在一个Bucket中OSD的个数 （每台机器数目3）

AFR: 磁盘的年平均故障率(谷歌数据： 1.7% ~ 8%, 由于我们使用普通磁盘本文以8%为标准)
FIT：单位时间（小时）的失效率
r : 机房单位时间(小时)磁盘损坏机率(r = FIT * N)


1）计算FIT单位时间（小时）失效率：
   FIT = AFR / (24*365） = 0.08 / (24*365) = 9.13e-6 （9.13e-6 代表 9.13*10^-6）

2）机房单位时间(小时)磁盘损坏机率
    r= FIT * N（机房磁盘数目）= 9.13e-6 * 12 = 0.000109 = 1.09e-4 


3）N个磁盘在单位时间内的失效率公式：
   Pn(r, t) = (r * t)^n * e^(-r * t)/ n！ （n代表多少个磁盘出现问题）


4）集群内部任意一个osd损坏机率

  机房单位时间(小时)磁盘损坏机率
  r = FIT * N = 9.13e-6 * 12 = 1.09e-4 

  计算一年内没有磁盘出现问题概率
  P0(r, t) = (0.09e-4 * 24 * 365)^0 * e^(-1.09e-4 * 24 * 365)/ 0! = 1 * e^(-1.09-4 * 24 * 365) = 2.718^(-0.95) = 0.386

  一年内任意一个以上osd出现问题情况 ：1 - 无osd出现问题情况

  P1(any) = 1 - P0 = 1 - 0.386 = 0.614

5）在恢复时间内第二， 三个节点出现故障的概率P2(any) P3(any)

  根据上面情况，我们磁盘容量为2T，磁盘使用率75%，我们目前按照机器进行平衡，当一个osd出现问题，有本机其他两个磁盘接管他的数据，每个磁盘磁盘速度50MB， 当一个osd损坏以后恢复时间计算如下：

  Tr = Capacity * Usage / (WriteSpeed * OSD_Good) = (2 * 1024GB * 0.75) / (50 * 2) = 15360


  r1 = FIT * (N - 1) = 1.00e-4

  P2(any) = 1 - P0(r, tr) = 1 - [(r1 * Tr)^0 * e ^ (-r1 * tr)/ 0!] = 1 - e^(-r1 * tr) = 1 - 2.718^(-1.00e-4 * (15360/3600)) 
          = 1 - 2.718^(-4.3e-4) = 0.000429

  r2 = FIT * (N - 2) = 9.13e-5

  P3(any) = 1 - P0(r, tr) = 1 - [(r2 * Tr)^0 * e ^ (-r2 * tr)/ 0!] = 1 - e^(-r1 * tr) = 1 - 2.718^(-9.13e-5 * (15360/3600)) 
          = 1 - 2.718^(0.000429) = 1 - 0.999616653 = 3.83e-4


6) 3个osd同时损坏概率是
   Pr = P1 * P2 * P3 = 0.000429 * 0.000383 * 0.614 = 1.01e-7

7) 在这个计算模型中， 因为任意3个OSD节点的损坏并不意外着副本的完全丢失，因为损坏的3个OSD未必保存着一个Object的全部副本信息，所以未必造成数据不可恢复，所 以这里引入了Copy Sets的概念。简单来说，Copyset就是存放所有拷贝的一个集合，具体的定义和计算方法可以查看参考链接。那么这里的场景下我们使用4台datanode， 每个datanode有3个磁盘(osd)，备份必须存放在不同机器上面， 假设copy set 数目为M

C(N, R) [组合数， N 代表元素总个数， R参与选择元素个数] 

M = C(4, 3) * C(3, 1) * C(3, 1) * C(3, 1) = 3 * 3 * 3 * 3 = 81

8）计算丢失copy set可能性

     P = Pr * M / C(N, R) = 1.01e-7 * 81 / C(12, 3) = 1.01e-7 * 81 / 220 = 3.7186e-8

  
ceph集群一年期稳定性Nines：

    1 - P = 1.0 - 3.7186e-08 = 0.99999996281


统计表：

硬盘容量：      2000GB
硬盘写速度：    50MB/S
硬盘使用率：    75%
故障域(1机器)：  3磁盘
恢复时间：       4.2小时（磁盘坏了， 磁盘数据需要4.2小时迁移其他2个磁盘）
P1：          0.614     (集群内部任意一个osd损坏机率)
P2：          0.000429  (在恢复时间内第二个磁盘出现问题机率)
P3：          0.000383  (在恢复时间内第三个磁盘出现问题机率) 
Pr：          1.01e-7  
M：                    

